{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ffe6316",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c535681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _nearest_index(target_ns: np.ndarray, grid_ns: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    For each target timestamp, return index of nearest grid timestamp.\n",
    "    grid_ns must be sorted ascending.\n",
    "    \"\"\"\n",
    "    idx = np.searchsorted(grid_ns, target_ns, side=\"left\")\n",
    "    idx0 = np.clip(idx - 1, 0, grid_ns.size - 1)\n",
    "    idx1 = np.clip(idx,     0, grid_ns.size - 1)\n",
    "\n",
    "    d0 = np.abs(target_ns - grid_ns[idx0])\n",
    "    d1 = np.abs(target_ns - grid_ns[idx1])\n",
    "    return np.where(d1 < d0, idx1, idx0)\n",
    "\n",
    "\n",
    "def load_self_report(self_report_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Input format:\n",
    "      timestamp,PainLevel,Action,Trial\n",
    "      2025-03-12 10:01:45.587,,Session Started,0\n",
    "      ...\n",
    "    Requirements:\n",
    "      - timestamps are EDT (America/New_York, UTC-4) -> convert to UTC\n",
    "      - Trial: ffill then bfill\n",
    "    \"\"\"\n",
    "    sr = pd.read_csv(self_report_csv)\n",
    "\n",
    "    # Parse timestamp as local (America/New_York) then convert to UTC\n",
    "    t_local = pd.to_datetime(sr[\"timestamp\"], errors=\"coerce\")\n",
    "    # Use America/New_York to correctly handle DST; March is usually EDT but this is safer.\n",
    "    t_utc = (t_local\n",
    "             .dt.tz_localize(\"America/New_York\", ambiguous=\"infer\", nonexistent=\"shift_forward\")\n",
    "             .dt.tz_convert(\"UTC\"))\n",
    "\n",
    "    sr[\"timestamp_utc\"] = t_utc\n",
    "    sr[\"timestamp_ns\"] = (sr[\"timestamp_utc\"]).astype(\"int64\")\n",
    "\n",
    "    # Fill Trial (ffill then bfill)\n",
    "    # Keep as numeric if possible, otherwise as string\n",
    "    if \"Trial\" in sr.columns:\n",
    "        trial = sr[\"Trial\"]\n",
    "        # Try numeric, but don't force\n",
    "        trial_num = pd.to_numeric(trial, errors=\"coerce\")\n",
    "        sr[\"Trial\"] = trial_num.ffill().bfill().astype(int)\n",
    "\n",
    "    return sr\n",
    "\n",
    "\n",
    "def join_self_report_to_physio(\n",
    "    physio_csv: str,\n",
    "    self_report_csv: str,\n",
    "    out_csv: str,\n",
    "    keep_action: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds PainLevel + Trial (and optionally Action) to physio df by snapping each\n",
    "    self-report PainLevel row to one nearest physio row.\n",
    "\n",
    "    \"excluding action\" interpreted as: do not include Action in the output\n",
    "    but keep rows that don't have PainLevel (session markers).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(physio_csv)\n",
    "    if \"timestamp_ns\" not in df.columns:\n",
    "        raise ValueError(f\"{physio_csv} missing timestamp_ns\")\n",
    "\n",
    "    df[\"timestamp_ns\"] = df[\"timestamp_ns\"].astype(\"int64\")\n",
    "    df = df.sort_values(\"timestamp_ns\", kind=\"mergesort\").reset_index(drop=True)\n",
    "    grid_ns = df[\"timestamp_ns\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "    sr = load_self_report(self_report_csv)\n",
    "\n",
    "    if sr.empty:\n",
    "        # still write output with empty PainLevel/Trial columns\n",
    "        df[\"PainLevel\"] = np.nan\n",
    "        df[\"Trial\"] = np.nan\n",
    "        os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "        df.to_csv(out_csv, index=False)\n",
    "        return df\n",
    "\n",
    "    target_ns = sr[\"timestamp_ns\"].to_numpy(dtype=np.int64)\n",
    "    nearest_idx = _nearest_index(target_ns, grid_ns)\n",
    "\n",
    "    # Prepare output columns\n",
    "    if \"PainLevel\" not in df.columns:\n",
    "        df[\"PainLevel\"] = np.nan\n",
    "    if \"Trial\" not in df.columns:\n",
    "        df[\"Trial\"] = np.nan\n",
    "    if keep_action and \"Action\" not in df.columns:\n",
    "        df[\"Action\"] = np.nan\n",
    "\n",
    "    # Assign (if multiple self-report rows map to the same physio row, later ones overwrite)\n",
    "    df.loc[nearest_idx, \"PainLevel\"] = sr[\"PainLevel\"].to_numpy()\n",
    "    if \"Trial\" in sr.columns:\n",
    "        df.loc[nearest_idx, \"Trial\"] = sr[\"Trial\"].to_numpy()\n",
    "    if keep_action and \"Action\" in sr.columns:\n",
    "        df.loc[nearest_idx, \"Action\"] = sr[\"Action\"].to_numpy()\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "    df['Trial'] = df['Trial'].ffill().bfill().astype(np.int32)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def batch_join(\n",
    "    merged_dir: str,\n",
    "    self_report_dir: str,\n",
    "    out_dir: str,\n",
    "    merged_glob: str = \"*_merged_64hz.csv\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Example directories:\n",
    "      merged_dir: ./processed_data/combined\n",
    "      self_report_dir: ./self_report\n",
    "      out_dir: ./processed_data/combined_with_self_report\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    merged_paths = sorted(glob.glob(os.path.join(merged_dir, merged_glob)))\n",
    "    if not merged_paths:\n",
    "        raise FileNotFoundError(f\"No merged files found in {merged_dir} with glob {merged_glob}\")\n",
    "\n",
    "    for phys_path in merged_paths:\n",
    "        base = os.path.basename(phys_path)\n",
    "        subject_id = base.split(\"_\")[0]  # e.g., \"003\" from \"003_merged_64hz.csv\"\n",
    "\n",
    "        # Try a few common self-report naming patterns\n",
    "        candidates = [\n",
    "            os.path.join(self_report_dir, f\"{subject_id}.csv\"),\n",
    "            os.path.join(self_report_dir, f\"{subject_id}_self_report.csv\"),\n",
    "            os.path.join(self_report_dir, f\"{subject_id}_selfreport.csv\"),\n",
    "        ]\n",
    "        sr_path = next((p for p in candidates if os.path.exists(p)), None)\n",
    "        if sr_path is None:\n",
    "            # fallback: any file containing subject_id\n",
    "            fallback = sorted(glob.glob(os.path.join(self_report_dir, f\"*{subject_id}*.csv\")))\n",
    "            sr_path = fallback[0] if fallback else None\n",
    "\n",
    "        if sr_path is None:\n",
    "            print(f\"[WARN] no self report for subject {subject_id}; skipping\")\n",
    "            continue\n",
    "\n",
    "        out_path = os.path.join(out_dir, f\"{subject_id}_merged_64hz_with_self_report.csv\")\n",
    "        print(f\"[OK] {subject_id}: {phys_path} + {sr_path} -> {out_path}\")\n",
    "        join_self_report_to_physio(phys_path, sr_path, out_path, keep_action=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27840dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 001: ./processed_data/per_subject/001_merged_64hz.csv + ./original_files/self_report/001.csv -> ./processed_data/with_self_report/per_subject/001_merged_64hz_with_self_report.csv\n",
      "[OK] 002: ./processed_data/per_subject/002_merged_64hz.csv + ./original_files/self_report/002.csv -> ./processed_data/with_self_report/per_subject/002_merged_64hz_with_self_report.csv\n",
      "[OK] 003: ./processed_data/per_subject/003_merged_64hz.csv + ./original_files/self_report/003.csv -> ./processed_data/with_self_report/per_subject/003_merged_64hz_with_self_report.csv\n",
      "[OK] 004: ./processed_data/per_subject/004_merged_64hz.csv + ./original_files/self_report/004.csv -> ./processed_data/with_self_report/per_subject/004_merged_64hz_with_self_report.csv\n",
      "[OK] 005: ./processed_data/per_subject/005_merged_64hz.csv + ./original_files/self_report/005.csv -> ./processed_data/with_self_report/per_subject/005_merged_64hz_with_self_report.csv\n",
      "[OK] 006: ./processed_data/per_subject/006_merged_64hz.csv + ./original_files/self_report/006.csv -> ./processed_data/with_self_report/per_subject/006_merged_64hz_with_self_report.csv\n",
      "[OK] 007: ./processed_data/per_subject/007_merged_64hz.csv + ./original_files/self_report/007.csv -> ./processed_data/with_self_report/per_subject/007_merged_64hz_with_self_report.csv\n"
     ]
    }
   ],
   "source": [
    "batch_join(\"./processed_data/per_subject\", \"./original_files/self_report\", \"./processed_data/with_self_report/per_subject\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
